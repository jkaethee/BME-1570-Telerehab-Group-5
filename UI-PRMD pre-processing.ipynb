{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5357a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from numpy import genfromtxt\n",
    "from pathlib import Path\n",
    "import math\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2829c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Functions\n",
    "\n",
    "def eulers_2_rot_matrix(x):\n",
    "    \"\"\"\n",
    "    EULER_2_ROT_MATRIX transforms a set of euler angles into a rotation  matrix \n",
    "    input vector of euler angles \n",
    "    [gamma_x, beta_y, alpha_z]  are ZYX Eulers angles in radians\n",
    "    \"\"\"\n",
    "    gamma_x=x[0];beta_y=x[1];alpha_z=x[2];\n",
    "    rot_z = rotz(alpha_z)\n",
    "    rot_y = roty(beta_y)\n",
    "    rot_x = rotx(gamma_x)\n",
    "    \n",
    "    R = rot_z * rot_y * rot_x\n",
    "    return R\n",
    "\n",
    "def rotx(t):\n",
    "    # ROTX Rotation about X axis\n",
    "    ct = math.cos(t);\n",
    "    st = math.sin(t);\n",
    "    r =  np.matrix([[1,\t0,\t0],\n",
    "                    [0,\tct,\t-st],\n",
    "                    [0,\tst,\tct]]);\n",
    "    return r\n",
    "\n",
    "def roty(t):\n",
    "    # ROTY Rotation about Y axis\n",
    "    ct = math.cos(t);\n",
    "    st = math.sin(t);\n",
    "    r =  np.matrix([[ct,\t0,\tst],\n",
    "                    [0,\t1,\t0],\n",
    "                    [-st\t,0,\tct]]);\n",
    "    return r\n",
    "\n",
    "def rotz(t):\n",
    "    # ROTZ Rotation about Z axis\n",
    "    ct = math.cos(t);\n",
    "    st = math.sin(t);\n",
    "    r = np.matrix([[ct, -st, 0],\n",
    "                   [st, ct, 0],\n",
    "                   [0, 0, 1]]);\n",
    "    return r\n",
    "    \n",
    "\n",
    "# Kinect data only has only one absolute position so we need to calculate absolute positions for remaining\n",
    "def rel2abs_kinect(pos, ang, skel):\n",
    "    num_joints, dimensions, num_frames = skel.shape\n",
    "    for i in range(num_frames):\n",
    "        \"\"\"\n",
    "        1 Waist (absolute)\n",
    "        2 Spine\n",
    "        3 Chest\n",
    "        4 Neck\n",
    "        5 Head\n",
    "        6 Head tip\n",
    "        7 Left collar\n",
    "        8 Left upper arm \n",
    "        9 Left forearm\n",
    "        10 Left hand\n",
    "        11 Right collar\n",
    "        12 Right upper arm \n",
    "        13 Right forearm\n",
    "        14 Right hand\n",
    "        15 Left upper leg \n",
    "        16 Left lower leg \n",
    "        17 Left foot \n",
    "        18 Left leg toes\n",
    "        19 Right upper leg \n",
    "        20 Right lower leg \n",
    "        21 Right foot\n",
    "        22 Right leg toes\n",
    "        \"\"\"\n",
    "        joint = pos[:,:,i]\n",
    "        joint_ang = ang[:,:,i]\n",
    "        \n",
    "        # chest, neck, head\n",
    "        rot_1 = eulers_2_rot_matrix(joint_ang[0,:]*np.pi/180)\n",
    "        joint[1,:] =  rot_1@joint[1,:] + joint[0,:]\n",
    "        rot_2 = rot_1*eulers_2_rot_matrix(joint_ang[1,:]*np.pi/180)\n",
    "        joint[2,:] =  rot_2@joint[2,:] +  joint[1,:]\n",
    "        rot_3 = rot_2*eulers_2_rot_matrix(joint_ang[2,:]*np.pi/180)\n",
    "        joint[3,:] =  rot_3@joint[3,:] +  joint[2,:]\n",
    "        rot_4 = rot_3*eulers_2_rot_matrix(joint_ang[3,:]*np.pi/180)\n",
    "        joint[4,:] =  rot_4@joint[4,:] +  joint[3,:]\n",
    "        rot_5 = rot_4*eulers_2_rot_matrix(joint_ang[4,:]*np.pi/180)\n",
    "        joint[5,:] =  rot_5@joint[5,:] +  joint[4,:]\n",
    "        \n",
    "        # left-arm\n",
    "        rot_6 = eulers_2_rot_matrix(joint_ang[2,:]*np.pi/180)\n",
    "        joint[6,:] =  rot_6@joint[6,:] +  joint[2,:]\n",
    "        rot_7 = rot_6*eulers_2_rot_matrix(joint_ang[6,:]*np.pi/180)\n",
    "        joint[7,:] =  rot_7@joint[7,:] +  joint[6,:]\n",
    "        rot_8 = rot_7*eulers_2_rot_matrix(joint_ang[7,:]*np.pi/180)\n",
    "        joint[8,:] = rot_8@joint[8,:] +  joint[7,:]\n",
    "        rot_9 = rot_8*eulers_2_rot_matrix(joint_ang[8,:]*np.pi/180)\n",
    "        joint[9,:] = rot_9@joint[9,:] +  joint[8,:]\n",
    "        \n",
    "        # right-arm\n",
    "        rot_10 = eulers_2_rot_matrix(joint_ang[2,:]*np.pi/180)\n",
    "        joint[10,:] =  rot_10@joint[10,:] +  joint[2,:]\n",
    "        rot_11 = rot_10*eulers_2_rot_matrix(joint_ang[10,:]*np.pi/180)\n",
    "        joint[11,:] =  rot_11@joint[11,:] +  joint[10,:]\n",
    "        rot_12 = rot_11*eulers_2_rot_matrix(joint_ang[11,:]*np.pi/180)\n",
    "        joint[12,:] = rot_12@joint[12,:] +  joint[11,:]\n",
    "        rot_13 = rot_12*eulers_2_rot_matrix(joint_ang[12,:]*np.pi/180)\n",
    "        joint[13,:] = rot_13@joint[13,:] +  joint[12,:]\n",
    "        \n",
    "        # left-leg\n",
    "        rot_14 = eulers_2_rot_matrix(joint_ang[0,:]*np.pi/180)\n",
    "        joint[14,:] =  rot_14@joint[14,:] +  joint[0,:]\n",
    "        rot_15 = rot_14*eulers_2_rot_matrix(joint_ang[14,:]*np.pi/180)\n",
    "        joint[15,:] =  rot_15@joint[15,:] +  joint[14,:]\n",
    "        rot_16 = rot_15*eulers_2_rot_matrix(joint_ang[15,:]*np.pi/180)\n",
    "        joint[16,:] = rot_16@joint[16,:] +  joint[15,:]\n",
    "        rot_17 = rot_16*eulers_2_rot_matrix(joint_ang[16,:]*np.pi/180)\n",
    "        joint[17,:] = rot_17@joint[17,:] +  joint[16,:]\n",
    "        \n",
    "        # right-leg\n",
    "        rot_18 = eulers_2_rot_matrix(joint_ang[0,:]*np.pi/180)\n",
    "        joint[18,:] =  rot_18@joint[18,:] +  joint[0,:]\n",
    "        rot_19 = rot_18*eulers_2_rot_matrix(joint_ang[18,:]*np.pi/180)\n",
    "        joint[19,:] =  rot_19@joint[19,:] +  joint[18,:]\n",
    "        rot_20 = rot_19*eulers_2_rot_matrix(joint_ang[19,:]*np.pi/180)\n",
    "        joint[20,:] = rot_20@joint[20,:] +  joint[19,:]\n",
    "        rot_21 = rot_20*eulers_2_rot_matrix(joint_ang[20,:]*np.pi/180)\n",
    "        joint[21,:] = rot_21@joint[21,:] +  joint[20,:]\n",
    "        skel[:,:,i] = joint\n",
    "    \n",
    "    return skel\n",
    "\n",
    "def getCommonFilenamePart(fileA, fileB, separator):\n",
    "    partA = fileA.split(separator)\n",
    "    partB = fileB.split(separator)\n",
    "    \n",
    "    common_components = []\n",
    "    \n",
    "    for (a, b) in zip(partA, partB):\n",
    "        if (a == b):\n",
    "            common_components.append(b) # keep adding while string match\n",
    "        else:\n",
    "            break;\n",
    "    return separator.join(common_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61dc4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KINECT - Filtering the raw data\n",
    "\n",
    "# Position directory setup\n",
    "correct_dir_pos_orig_kinect = \"Segmented Movements/Kinect/Positions\"\n",
    "incorrect_dir_pos_orig_kinect = \"Incorrect Segmented Movements/Kinect/Positions\"\n",
    "correct_dir_ang_orig_kinect = \"Segmented Movements/Kinect/Angles\"\n",
    "incorrect_dir_ang_orig_kinect = \"Incorrect Segmented Movements/Kinect/Angles\"\n",
    "\n",
    "path_to_correct_pos_kinect = Path(correct_dir_pos_orig_kinect)\n",
    "path_to_incorrect_pos_kinect = Path(incorrect_dir_pos_orig_kinect)\n",
    "path_to_correct_ang_kinect = Path(correct_dir_ang_orig_kinect)\n",
    "path_to_incorrect_ang_kinect = Path(incorrect_dir_ang_orig_kinect)\n",
    "paths_original_kinect = [path_to_correct_pos_kinect, path_to_incorrect_pos_kinect, path_to_correct_ang_kinect, path_to_incorrect_ang_kinect]\n",
    "\n",
    "# Angles directory setup\n",
    "correct_dir_pos_filt_kinect = \"Filtered Segmented Movements/Kinect/Positions\"\n",
    "incorrect_dir_pos_filt_kinect = \"Filtered Incorrect Segmented Movements/Kinect/Positions\"\n",
    "correct_dir_ang_filt_kinect = \"Filtered Segmented Movements/Kinect/Angles\"\n",
    "incorrect_dir_ang_filt_kinect = \"Filtered Incorrect Segmented Movements/Kinect/Angles\"\n",
    "\n",
    "# Create Path objects\n",
    "path_to_correct_filtered_pos_kinect = Path(correct_dir_pos_filt_kinect)\n",
    "path_to_incorrect_filtered_pos_kinect = Path(incorrect_dir_pos_filt_kinect)\n",
    "path_to_correct_filtered_ang_kinect = Path(correct_dir_ang_filt_kinect)\n",
    "path_to_incorrect_filtered_ang_kinect = Path(incorrect_dir_ang_filt_kinect)\n",
    "\n",
    "# Create directories\n",
    "path_to_correct_filtered_pos_kinect.mkdir(parents=True, exist_ok=True)\n",
    "path_to_incorrect_filtered_pos_kinect.mkdir(parents=True, exist_ok=True)\n",
    "path_to_correct_filtered_ang_kinect.mkdir(parents=True, exist_ok=True)\n",
    "path_to_incorrect_filtered_ang_kinect.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for directory in paths_original_kinect:\n",
    "#     for file_path in directory.iterdir():\n",
    "#         if file_path.is_file():\n",
    "#             read_data = genfromtxt(file_path, delimiter=',')        \n",
    "#             # Work through 3 columns at a time (one joint)\n",
    "#             for i in range(0, read_data.shape[1], 3):\n",
    "#                 joint_coordinate_slice = read_data[:, i:i+3]\n",
    "#                 filtered_joint = joint_coordinate_slice.copy()\n",
    "\n",
    "#                 # Use Savitzky-Golay Smoothing filter on each dimension separately\n",
    "#                 # Window length = 5\n",
    "#                 # Polynomial order = 2\n",
    "#                 for j in range(0, 3):\n",
    "#                     dimension_slice = filtered_joint[:, j]\n",
    "#                     # apply filter Savitzky-Golay filter to the dimension of joint across all time points\n",
    "#                     filtered_data = savgol_filter(dimension_slice, window_length=5, polyorder=2)\n",
    "#                     read_data[:, i+j] = filtered_data # Save new positional data\n",
    "\n",
    "#             smooth_file = \"smooth_\" + file_path.name\n",
    "#             # Save the filtered data as correct or incorrect in new directories\n",
    "#             if \"angle\" in file_path.name:\n",
    "#                 if \"Incorrect\" in str(directory.parent):\n",
    "#                     np.savetxt(f'{incorrect_dir_ang_filt_kinect}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#                 else:\n",
    "#                     np.savetxt(f'{correct_dir_ang_filt_kinect}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#             else:\n",
    "#                 if \"Incorrect\" in str(directory.parent):\n",
    "#                     np.savetxt(f'{incorrect_dir_pos_filt_kinect}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#                 else:\n",
    "#                     np.savetxt(f'{correct_dir_pos_filt_kinect}/{smooth_file}', read_data, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5bee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VICON - Filtering the raw data\n",
    "\n",
    "# Position directory setup\n",
    "correct_dir_pos_orig_vicon = \"Segmented Movements/Vicon/Positions\"\n",
    "incorrect_dir_pos_orig_vicon = \"Incorrect Segmented Movements/Vicon/Positions\"\n",
    "correct_dir_ang_orig_vicon = \"Segmented Movements/Vicon/Angles\"\n",
    "incorrect_dir_ang_orig_vicon = \"Incorrect Segmented Movements/Vicon/Angles\"\n",
    "\n",
    "path_to_correct_pos_vicon = Path(correct_dir_pos_orig_vicon)\n",
    "path_to_incorrect_pos_vicon = Path(incorrect_dir_pos_orig_vicon)\n",
    "path_to_correct_ang_vicon = Path(correct_dir_ang_orig_vicon)\n",
    "path_to_incorrect_ang_vicon = Path(incorrect_dir_ang_orig_vicon)\n",
    "paths_original_vicon = [path_to_correct_pos_vicon, path_to_incorrect_pos_vicon, path_to_correct_ang_vicon, path_to_incorrect_ang_vicon]\n",
    "\n",
    "# Angles directory setup\n",
    "correct_dir_pos_filt_vicon = \"Filtered Segmented Movements/Vicon/Positions\"\n",
    "incorrect_dir_pos_filt_vicon = \"Filtered Incorrect Segmented Movements/Vicon/Positions\"\n",
    "correct_dir_ang_filt_vicon = \"Filtered Segmented Movements/Vicon/Angles\"\n",
    "incorrect_dir_ang_filt_vicon = \"Filtered Incorrect Segmented Movements/Vicon/Angles\"\n",
    "\n",
    "# Create Path objects\n",
    "path_to_correct_filtered_pos_vicon = Path(correct_dir_pos_filt_vicon)\n",
    "path_to_incorrect_filtered_pos_vicon = Path(incorrect_dir_pos_filt_vicon)\n",
    "path_to_correct_filtered_ang_vicon = Path(correct_dir_ang_filt_vicon)\n",
    "path_to_incorrect_filtered_ang_vicon = Path(incorrect_dir_ang_filt_vicon)\n",
    "\n",
    "# Create directories\n",
    "path_to_correct_filtered_pos_vicon.mkdir(parents=True, exist_ok=True)\n",
    "path_to_incorrect_filtered_pos_vicon.mkdir(parents=True, exist_ok=True)\n",
    "path_to_correct_filtered_ang_vicon.mkdir(parents=True, exist_ok=True)\n",
    "path_to_incorrect_filtered_ang_vicon.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for directory in paths_original_vicon:\n",
    "#     for file_path in directory.iterdir():\n",
    "#         if file_path.is_file():\n",
    "#             read_data = genfromtxt(file_path, delimiter=',')        \n",
    "#             # Work through 3 columns at a time (one joint)\n",
    "#             # Avoids case like m10_s05_e09_positions_inc.txt, (117,) in Vicon dataset\n",
    "#             if (len(read_data.shape) != 2):\n",
    "#                 print('read_data.shape for file: ', f'{file_path.name}, {read_data.shape}');\n",
    "#                 continue;\n",
    "#             for i in range(0, read_data.shape[1], 3):\n",
    "#                 joint_coordinate_slice = read_data[:, i:i+3]\n",
    "#                 filtered_joint = joint_coordinate_slice.copy()\n",
    "\n",
    "#                 # Use Savitzky-Golay Smoothing filter on each dimension separately\n",
    "#                 # Window length = 5\n",
    "#                 # Polynomial order = 2\n",
    "#                 for j in range(0, 3):\n",
    "#                     dimension_slice = filtered_joint[:, j]\n",
    "#                     # apply filter Savitzky-Golay filter to the dimension of joint across all time points\n",
    "#                     filtered_data = savgol_filter(dimension_slice, window_length=5, polyorder=2)\n",
    "#                     read_data[:, i+j] = filtered_data # Save new positional data\n",
    "\n",
    "#             smooth_file = \"smooth_\" + file_path.name\n",
    "#             # Save the filtered data as correct or incorrect in new directories\n",
    "#             if \"angle\" in file_path.name:\n",
    "#                 if \"Incorrect\" in str(directory.parent):\n",
    "#                     np.savetxt(f'{incorrect_dir_ang_filt}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#                 else:\n",
    "#                     np.savetxt(f'{correct_dir_ang_filt}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#             else:\n",
    "#                 if \"Incorrect\" in str(directory.parent):\n",
    "#                     np.savetxt(f'{incorrect_dir_pos_filt}/{smooth_file}', read_data, delimiter=',', fmt='%f')\n",
    "#                 else:\n",
    "#                     np.savetxt(f'{correct_dir_pos_filt}/{smooth_file}', read_data, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1081cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Visualization 3D \n",
    "def visualize_skeleton(skel, gif_name):\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    # order of joint connections\n",
    "    J = np.array([[3, 5, 4, 2, 1, 2, 6, 7, 8, 2, 10, 11, 12, 0, 14, 15, 16, 0, 18, 19, 20],\n",
    "                  [2, 4, 2, 1, 0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]])\n",
    "    \n",
    "    max_x = skel[:, 0, :].max()\n",
    "    min_x = skel[:, 0, :].min()\n",
    "    max_y=  skel[:, 1, :].max()\n",
    "    min_y = skel[:, 1, :].min()\n",
    "    max_z = skel[:, 2, :].max()\n",
    "    min_z = skel[:, 2, :].min()\n",
    "\n",
    "    def get_plot(i):\n",
    "        ax.cla()\n",
    "\n",
    "        ax.set_title('3D plot using transformed data')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_zlabel('z')\n",
    "\n",
    "        ax.set_box_aspect([0, 1, 0])\n",
    "\n",
    "#         ax.set_xlim([min_x, max_x])\n",
    "#         ax.set_ylim([min_y, max_y])\n",
    "#         ax.set_zlim([min_z, max_z])\n",
    "        \n",
    "        ax.set_xlim([-5, 5])\n",
    "        ax.set_ylim([-5, 5])\n",
    "        ax.set_zlim([-5, 5])\n",
    "\n",
    "        joint = skel[:, :, i]\n",
    "\n",
    "        for j in range(J.shape[1]):\n",
    "            p1 = joint[J[0, j], :]\n",
    "            p2 = joint[J[1, j], :]\n",
    "            ax.plot([p1[2],p2[2]],[p1[0], p2[0]], [p1[1], p2[1]], 'bo-')\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, get_plot, blit=False, frames=skel.shape[2])\n",
    "    anim.save(gif_name, writer='Pillow', fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b0d1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skeletal data from each files filtered position + angular data\n",
    "paths_filtered = [(path_to_correct_filtered_pos_kinect, path_to_correct_filtered_ang_kinect),\n",
    "                  (path_to_incorrect_filtered_pos_kinect, path_to_incorrect_filtered_ang_kinect)]\n",
    "#                   (path_to_correct_filtered_pos_vicon, path_to_correct_filtered_ang_vicon),\n",
    "#                   (path_to_incorrect_filtered_pos_vicon, path_to_incorrect_filtered_ang_vicon)]\n",
    "\n",
    "paths_normal = [(path_to_correct_pos_kinect, path_to_correct_ang_kinect),\n",
    "                  (path_to_incorrect_pos_kinect, path_to_incorrect_ang_kinect),\n",
    "                  (path_to_correct_filtered_pos_vicon, path_to_correct_ang_vicon),\n",
    "                  (path_to_incorrect_pos_vicon, path_to_incorrect_ang_vicon)]\n",
    "\n",
    "# Initialize Skeletal data directory if doesn't already exist\n",
    "skel_kinect = \"Skeletal Data Filtered/Kinect\"\n",
    "skel_vicon = \"Skeletal Data Filtered/Vicon\"\n",
    "path_skel_kinect = Path(skel_kinect)\n",
    "path_skel_vicon = Path(skel_vicon)\n",
    "path_skel_kinect.mkdir(parents=True, exist_ok=True)\n",
    "path_skel_vicon.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for pos_dir, ang_dir in paths_filtered:\n",
    "#     # Make sure files are sorted the same way\n",
    "#     pos_sorted = sorted(os.listdir(pos_dir))\n",
    "#     ang_sorted = sorted(os.listdir(ang_dir))\n",
    "    \n",
    "#     inc_dir = \"Incorrect\" in str(pos_dir)\n",
    "    \n",
    "#     # Zip the lists together to iterate at the same time\n",
    "#     for (pos_file, ang_file) in zip(pos_sorted, ang_sorted):\n",
    "#         pos_file_path = f'{pos_dir}/{pos_file}'\n",
    "#         ang_file_path = f'{ang_dir}/{ang_file}'\n",
    "        \n",
    "#         pos_data = genfromtxt(pos_file_path, delimiter=',')\n",
    "#         ang_data = genfromtxt(ang_file_path, delimiter=',')\n",
    "        \n",
    "#         assert (pos_data.shape == ang_data.shape) # Make sure data size matches\n",
    "        \n",
    "#         # Skeletal data has shape [Joints x XYZ x Frames]\n",
    "#         frames, xyz_joints = pos_data.shape\n",
    "#         dimensions = 3\n",
    "#         joint_count = xyz_joints // dimensions\n",
    "        \n",
    "#         # Reshape into [Joints x XYZ x Frames] for position and angular data\n",
    "#         pos_data = pos_data.T.reshape(joint_count, 3, frames)\n",
    "#         ang_data = ang_data.T.reshape(joint_count, 3, frames )\n",
    "        \n",
    "#         # Initialize empty matrix for skeleton\n",
    "#         skeleton = np.zeros((joint_count, dimensions, frames))\n",
    "        \n",
    "#         # Kinect data relative to absolute coordinates\n",
    "#         if \"Kinect\" in str(pos_dir):\n",
    "#             skeleton = rel2abs_kinect(pos_data, ang_data, skeleton)\n",
    "#             file_name = \"\"\n",
    "#             if (inc_dir == True):\n",
    "#                 file_name = getCommonFilenamePart(pos_file, ang_file, '_') + \"_inc\" +\"_skeleton\" \n",
    "#             else :\n",
    "#                 file_name = getCommonFilenamePart(pos_file, ang_file, '_') + \"_skeleton\"\n",
    "            \n",
    "#             print(\"Saving file: \", file_name)\n",
    "#             np.save(f'{skel_kinect}/{file_name}', skeleton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a5c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify skeleton data works through animation:\n",
    "# test_skel = np.load('Skeletal Data Filtered/Kinect/smooth_m01_s01_e01_skeleton.npy')\n",
    "# test_skel_inc = np.load('Skeletal Data Filtered/Kinect/smooth_m01_s01_e01_inc_skeleton.npy')\n",
    "# test_skel_normal = np.load('Skeletal Data Normal/Kinect/m01_s01_e01_skeleton.npy')\n",
    "# test_skel_normal_inc = np.load('Skeletal Data Normal/Kinect/m01_s01_e01_inc_skeleton.npy')\n",
    "# visualize_skeleton(test_skel, 'filt_skel.gif')\n",
    "# visualize_skeleton(test_skel_inc, 'filt_skel_inc.gif')\n",
    "# visualize_skeleton(test_skel_normal, 'normal_skel.gif')\n",
    "# visualize_skeleton(test_skel_normal_inc, 'normal_skel_inc.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2993bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale normalization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def scale_normalization(skeleton):\n",
    "    \"\"\"\n",
    "    Normalizes skeleton based on the average distance between the joint ‘‘hip center’’ and the joint ‘‘spine’’ \n",
    "    of all skeleton data in a sequence\n",
    "    \n",
    "    R. Li, H. Fu, W.-L. Lo, Z. Chi, Z. Song, and D. Wen, “Skeleton-Based Action Recognition With Key-Segment Descriptor and Temporal Step Matrix Model,” IEEE Access, vol. 7, pp. 169782–169795, 2019, doi: 10.1109/ACCESS.2019.2954744.\n",
    "\n",
    "    Param:\n",
    "    - skeleton: np.array (joints, 3, frames)\n",
    "    \"\"\"\n",
    "    joints = skeleton.shape[0]\n",
    "    frames = skeleton.shape[2]\n",
    "    \n",
    "    hip_coords = skeleton[0, :, :]\n",
    "    spine_coords = skeleton[1, :, :]\n",
    "    \n",
    "    # First do view alignment\n",
    "    o = np.mean(hip_coords, axis=1) # Average of hip center of all frames\n",
    "        \n",
    "    # Translate all skeletons to new origin\n",
    "    skeleton = skeleton - o[:, np.newaxis]\n",
    "        \n",
    "    euclidean_distances = []\n",
    "    \n",
    "    for i in range(frames):\n",
    "        euclidean_distances.append(np.linalg.norm(hip_coords[:, i] - spine_coords[:, i]))\n",
    "    \n",
    "\n",
    "    # d_1_2 is the average distance between the joint ‘‘hip center’’ and the joint ‘‘spine’’\n",
    "    d_1_2 = np.mean(euclidean_distances)\n",
    "        \n",
    "    # scale joints according to this length\n",
    "#     new_skeleton = skeleton/d_1_2\n",
    "    new_skeleton = np.zeros_like(skeleton)\n",
    "    for frame in range(frames):\n",
    "        for joint in range(joints):\n",
    "            j_kn = skeleton[joint, :, frame] # original position\n",
    "            j_1n = skeleton[0, :, frame] # hip coordinate\n",
    "            \n",
    "            j_hat_kn = ((1/d_1_2) * (j_kn)) \n",
    "            \n",
    "            new_skeleton[joint, :, frame] = j_hat_kn\n",
    "\n",
    "    \n",
    "    return new_skeleton\n",
    "    \n",
    "\n",
    "filtered_skeleton_dir = \"Skeletal Data Filtered/Kinect\"\n",
    "skel_dir = Path(filtered_skeleton_dir)\n",
    "\n",
    "normalized_dir = Path(\"Scale Normalized Filtered Skeletal Data\")\n",
    "normalized_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file_path in skel_dir.iterdir():\n",
    "    if file_path.is_file():\n",
    "        skeleton = np.load(file_path) # load .npy file\n",
    "        normalized_skeleton = scale_normalization(skeleton)\n",
    "        file_name = \"scale_norm_\" + file_path.name\n",
    "        np.save(f'Scale Normalized Filtered Skeletal Data/{file_name}', normalized_skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c60f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_skel = np.load('Skeletal Data Filtered/Kinect/smooth_m09_s01_e01_inc_skeleton.npy')\n",
    "# test_skel_norm = np.load('Scale Normalized Filtered Skeletal Data/scale_norm_smooth_m04_s01_e01_inc_skeleton.npy')\n",
    "# # visualize_skeleton(test_skel, 'filt_skel_inc.gif')\n",
    "# visualize_skeleton(test_skel_norm, 'filt_skel_inc_norm.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_dict = {\n",
    "    'm01':'deep squat',\n",
    "    'm02':'hurdle step',\n",
    "    'm03':'inline lunge',\n",
    "    'm04':'side lunge',\n",
    "    'm05':'sit to stand',\n",
    "    'm06':'standing active leg raise',\n",
    "    'm07':'standing shoulder abduction',\n",
    "    'm08':'standing shoulder extension',\n",
    "    'm09':'standing shoulder internal-external rotation',\n",
    "    'm10':'standing shoulder scaption' \n",
    "}\n",
    "\n",
    "exercise_number_dict = {\n",
    "    'm01':1,\n",
    "    'm02':2,\n",
    "    'm03':3,\n",
    "    'm04':4,\n",
    "    'm05':5,\n",
    "    'm06':6,\n",
    "    'm07':7,\n",
    "    'm08':8,\n",
    "    'm09':9,\n",
    "    'm10':10 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb631acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to input format for MMAction2\n",
    "import glob\n",
    "import re\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Dictionary to store data per subject\n",
    "subject_data = defaultdict(list)\n",
    "\n",
    "exercises_npy = [file for file in glob.glob(\"Scale Normalized Filtered Skeletal Data/*.npy\")]\n",
    "assert (len(exercises_npy) == 2000)\n",
    "\n",
    "for file, exercise_data in enumerate(exercises_npy):\n",
    "    frame_dir = \"\"\n",
    "    \n",
    "    # Get exercise name\n",
    "    exercise_name_match = re.search(r\"m\\d{2}\", exercise_data) # searches for 'm' followed by 2 digits\n",
    "    exercise_name = \"\"\n",
    "    if exercise_name_match:\n",
    "        key = exercise_name_match.group(0)\n",
    "        exercise_name = exercise_dict.get(key, \"Unknown exercise\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Key not found in the input string.\")\n",
    "        \n",
    "    # Get identifier (frame_dir)\n",
    "    identifier_match = re.search(r\"_s\\d{2}_e\\d{2}\", exercise_data)    \n",
    "    identifier_name = \"\"\n",
    "    if identifier_match:\n",
    "        identifier_name = identifier_match.group(0)\n",
    "    else:\n",
    "        print(\"Pattern not found: \", exercise_name)\n",
    "    \n",
    "    frame_dir = exercise_name + identifier_name\n",
    "    \n",
    "    # Get correct or incorrect - label 0 for incorrect, 1 for correct\n",
    "    incorrect_match = re.search(r\"inc\", exercise_data)\n",
    "    if incorrect_match:\n",
    "        frame_dir += \"_inc\"\n",
    "        label = 0\n",
    "    else:\n",
    "        frame_dir += \"_corr\"\n",
    "        label = 1\n",
    "            \n",
    "    # Prepare other values for dictionary\n",
    "    exercise_npy = np.load(exercise_data) # Shape (22x3xnum_frames)\n",
    "    \n",
    "    total_frames = exercise_npy.shape[2]\n",
    "    \n",
    "    # Keypoint format requires 4d array of size [MxTxVxC] - data is currently [VxCxT]\n",
    "    exercise_npy_transposed = exercise_npy.transpose(2,0,1) # Puts it in [TxVxC]\n",
    "    keypoint = np.expand_dims(exercise_npy_transposed, axis=0) # Adds in M dimension\n",
    "    keypoint[0,:,:,:] = 1 # M = number of persons\n",
    "    \n",
    "    exercise_json = {\n",
    "        'frame_dir': frame_dir,\n",
    "        'label': int(label),\n",
    "        'total_frames':total_frames,\n",
    "        'keypoint':keypoint,\n",
    "        'exercise_name':exercise_name # Extra key-value for identifying type of exercise\n",
    "    }    \n",
    "    \n",
    "    # Extract subject ID (e.g., 's01') and store in subject_data dictionary\n",
    "    subject_match = re.search(r\"s\\d{2}\", identifier_name)\n",
    "    if subject_match:\n",
    "        subject_id = subject_match.group(0)\n",
    "        subject_data[subject_id].append(exercise_json)\n",
    "    else:\n",
    "        print(\"Subject ID not found in:\", exercise_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a4e55f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pkl file LOSO split for leaving out subject s01\n",
      "Saving pkl file LOSO split for leaving out subject s02\n",
      "Saving pkl file LOSO split for leaving out subject s03\n",
      "Saving pkl file LOSO split for leaving out subject s04\n",
      "Saving pkl file LOSO split for leaving out subject s05\n",
      "Saving pkl file LOSO split for leaving out subject s06\n",
      "Saving pkl file LOSO split for leaving out subject s07\n",
      "Saving pkl file LOSO split for leaving out subject s08\n",
      "Saving pkl file LOSO split for leaving out subject s09\n",
      "Saving pkl file LOSO split for leaving out subject s10\n",
      "LOSO split files with annotations saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create and save LOSO splits\n",
    "for subject_id, val_data in subject_data.items():\n",
    "    \n",
    "    # Training data is all other subjects\n",
    "    train_data = [item for sid, data in subject_data.items() if sid != subject_id for item in data]\n",
    "    \n",
    "    # Define the input files for MMAction2\n",
    "    loso_data = {\n",
    "        \"split\": {\n",
    "            \"xsub_train\": [item['frame_dir'] for item in train_data],\n",
    "            \"xsub_val\": [item['frame_dir'] for item in val_data]\n",
    "        },\n",
    "        \"annotations\": train_data + val_data  # Include all data\n",
    "    }\n",
    "        \n",
    "    # Save to a pickle file for each LOSO split\n",
    "    with open(f'loso_split_{subject_id}.pkl', 'wb') as f:\n",
    "        pickle.dump(loso_data, f)\n",
    "    \n",
    "    print(f\"Saving pkl file LOSO split for leaving out subject {subject_id}\")\n",
    "\n",
    "print(\"LOSO split files with annotations saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31513b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
